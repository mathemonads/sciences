%!/usr/bin/env latex

\section{Quantum Mechanics}

\subsection{Systems and experiments}

% ket linearity
\begin{answer}[Inner product]
	Consider any $\bra{A}$.
	\begin{enumerate}
		\item To show $\left\{\bra{A} + \bra{B}\right\} \ket{C} = \braket{A \mid C} + \braket{B \mid C}$, let $\ket{A}$ and $\ket{B}$ be ket-vectors whose bra-vectors are $\bra{A}$ and $\bra{B}$ respectively.

		      There is a ket-vector $\ket{D} = \ket{A} + \ket{B}$.
		      Its bra vector $\bra{D}$ is given by $\bra{D} = \bra{A} + \bra{B}$.
		      Interchanging bras and kets yields the following.
		      \begin{align}\label{eqn:interchange}
			      \braket{D \mid C} = \braket{C \mid D}^* = \left(\braket{C \mid A} + \braket{C \mid B}\right)^* = \braket{C \mid A}^* + \braket{C \mid B}^*
		      \end{align}
		      The final equation follows from linearity of complex conjugation.
		      Complex conjugation of each term in the right-hand expression in Equation \eqref{eqn:interchange} yields $\braket{D \mid C} = \braket{A \mid C} + \braket{B \mid C}$.
		\item To show that the complex number $\braket{A \mid A}$ is a real number for any ket-vector $\ket{A}$, recall that interchanging bras and kets yields a complex number $\braket{A \mid A} = \braket{A \mid A}^*$ that is its own complex conjugate.
		      It follows that its imaginary component is zero and thus that it is real.
	\end{enumerate}
\end{answer}

% calculation
\begin{answer}[Component-wise inner product]
	To show the operation given for any natural number $n$ in terms of components by
	\begin{align*}
		\braket{B \mid A} & =
		\begin{pmatrix}
			\beta_1^* & \beta_2^* & \cdots & \beta_{n-1}^* & \beta_n^*
		\end{pmatrix}
		\begin{pmatrix}
			\alpha_1     \\
			\alpha_2     \\
			\cdots       \\
			\alpha_{n-1} \\
			\alpha_n
		\end{pmatrix}                                                                                                           \\
		                  & = \beta_1^* \alpha_1 + \beta_2^* \alpha_2 + \cdots + \beta_{n-1}^* \alpha_{n-1} + \beta_n^* \alpha_n
	\end{align*}
	is an inner product, observe that it is sesquilinear
	\begin{align*}
		\bra{C} \{ \ket{A} + \ket{B} \} & = \sum_{k=1}^n \gamma_k^* \left(\alpha_k+\beta_k\right) = \sum_{i=1}^n \gamma_i^* \alpha_i + \sum_{j=1}^n \gamma_j^* \beta_j =
		\braket{C \mid A} + \braket{C \mid B}.
	\end{align*}
	and that interchanging bras and kets yields
	\begin{align}
		\braket{B \mid A} = \sum_{k=1}^n \beta_k^* \alpha_k = \left(\sum_{k=1}^n \alpha_k^* \beta_k\right)^* = \braket{A \mid B}^*
	\end{align}
	since $\left(\alpha_k^* \beta_k\right)^* = \beta_k^* \alpha_k$ holds for all $k \leq n$.

	Observe $\dsp \bra{B} \{ z \ket{A} \} = \sum_{k=1}^n \beta_k^* \left(z \alpha_k\right) = z \sum_{k=1}^n \beta_k^* \alpha_k = z \braket{B \mid A}$.
	Conjugate-linearity in the first argument follows immediately from the definition.
	Any ket-vector $\ket{A}$ satisfies $\dsp \braket{A \mid A} = \sum_{k=1}^n \alpha_k^* \alpha_k = \sum_{k=1}^n \left|\alpha_k\right|^2 \geq 0$, and the equation $\braket{A \mid A} = 0$ holds iff $\ket{A} = \ket{0}$.
\end{answer}

\subsection{Quantum state}

% orthogonality of u and d
\begin{answer}[Orthogonality of $r$ and $l$]
	The inner product of the vectors $\dsp \ket{r} = \frac{1}{\sqrt{2}} \ket{u} + \frac{1}{\sqrt{2}} \ket{d}$ and $\dsp \ket{l} = \frac{1}{\sqrt{2}} \ket{u} - \frac{1}{\sqrt{2}} \ket{d}$ is $\frac{1}{2} - \frac{1}{2} = 0$, since $\ket{u}$ and $\ket{d}$ are mutually orthonormal.
	Therefore, the vector $\ket{r}$ is orthogonal to $\ket{l}$.
\end{answer}

% components of bra are conjugated
\begin{answer}[Orthonormality of $i$ and $o$]
	Let $\ket{r} = \frac{1}{\sqrt{2}} \ket{u} + \frac{1}{\sqrt{2}} \ket{d}$, $\ket{l} = \frac{1}{\sqrt{2}} \ket{u} - \frac{1}{\sqrt{2}} \ket{d}$, $\ket{i} = \frac{1}{\sqrt{2}} \ket{u} + \frac{i}{\sqrt{2}} \ket{d}$ and $\ket{o} = \frac{1}{\sqrt{2}} \ket{u} - \frac{i}{\sqrt{2}} \ket{d}$.
	Since $\ket{u}$ and $\ket{d}$ are mutually orthonormal, we obtain orthogonality as shown below.
	\begin{align*}
		\braket{i \mid o} & = \frac{1}{2} + \left(\frac{i}{\sqrt{2}}\right)^* \left(-\frac{i}{\sqrt{2}}\right) = 0
	\end{align*}
	By orthonormality, we also obtain the following equations.
	\begin{align*}
		\braket{o \mid u} \braket{u \mid o} & = \frac{1}{\sqrt{2}} \frac{1}{\sqrt{2}} = \frac{1}{2}                                     \\
		\braket{o \mid d} \braket{d \mid o} & = \left(-\frac{i}{\sqrt{2}}\right)^* \cdot \left(-\frac{i}{\sqrt{2}}\right) = \frac{1}{2} \\
		\braket{i \mid u} \braket{u \mid i} & = \frac{1}{\sqrt{2}} \frac{1}{\sqrt{2}} = \frac{1}{2}                                     \\
		\braket{i \mid d} \braket{d \mid i} & = \left(\frac{i}{\sqrt{2}}\right)^* \left(\frac{i}{\sqrt{2}}\right) = \frac{1}{2}
	\end{align*}
	Similarly, we obtain the following equations.
	\begin{align*}
		\braket{o \mid r} \braket{r \mid o} & = \left(\frac{1}{2} + (-\frac{i}{\sqrt{2}})^* \frac{1}{\sqrt{2}}\right)\left(\frac{1}{2} + \frac{1}{\sqrt{2}}(-\frac{i}{\sqrt{2}}) \right) = \frac{1}{4} + \frac{-i^2}{4} = \frac{1}{2} \\
		\braket{o \mid l} \braket{l \mid o} & = \left(\frac{1 + (-i)^*(-1)}{2}\right)\left(\frac{1 + (-1)(-i)}{2}\right) = \frac{1-i^2}{4} = \frac{1}{2}                                                                              \\
		\braket{i \mid r} \braket{r \mid i} & = \frac{\left(1 -i\right)\left(1 + i\right)}{4} = \frac{1 - i^2}{4} = \frac{1}{2}                                                                                                       \\
		\braket{i \mid l} \braket{l \mid i} & = \frac{\left(1 + i\right)\left(1 - i\right)}{4} = \frac{1 + 1}{4} = \frac{1}{2}
	\end{align*}
	Among pairs of orthogonal vectors satisfying all of the eight equations shown above, the pair of orthogonal vectors $\ket{i}$ and $\ket{o}$ is not strictly unique.
\end{answer}

% calculation
\begin{answer}
	Let $\ket{u}$ and $\ket{d}$ be an orthonormal basis of a single spin-$\frac{1}{2}$ system.
	Let $\ket{i} = \alpha \ket{u} + \beta \ket{d}$ and $\ket{o} = \gamma \ket{u} + \delta \ket{d}$ be given in terms of unknown components $\alpha$, $\beta$, $\gamma$, and $\delta$.
	Suppose they are a pair of orthonormal vectors satisfying the equations of the previous exercise.
	Note $\braket{u \mid i} = \alpha$, $\braket{d \mid i} = \beta$, $\braket{u \mid o} = \gamma$, and $\braket{d \mid o} = \delta$.
	Their complex conjugates are $\braket{i \mid u} = \alpha^*$, $\braket{i \mid d} = \beta^*$, $\braket{o \mid u} = \gamma^*$, and $\braket{o \mid d} = \delta^*$.
	\begin{enumerate}
		\item Calculation yields $\alpha^* \alpha = \braket{i \mid u} \braket{u \mid i} = \frac{1}{2}$ and $\beta^* \beta = \braket{i \mid d} \braket{d \mid i} = \frac{1}{2}$.
		      Similarly, it follows that $\gamma^* \gamma = \braket{o \mid u} \braket{u \mid o} = \frac{1}{2}$ and $\delta^* \delta = \braket{o \mid d} \braket{d \mid o} = \frac{1}{2}$.
		      Thus, there is a set $\left\{\theta_j \in \R \mid 1 \leq j \leq 4 \right\}$ of phases such that $\alpha = \frac{1}{\sqrt{2}} e^{i \theta_1}$, $\beta = \frac{1}{\sqrt{2}} e^{i \theta_2}$, $\gamma = \frac{1}{\sqrt{2}} e^{i \theta_3}$, and $\delta = \frac{1}{\sqrt{2}} e^{i \theta_4}$.
		\item Recall $\ket{r} = \frac{1}{\sqrt{2}}\left(\ket{u} + \ket{d}\right)$.

		      Since $\braket{r \mid i} = \frac{1}{\sqrt{2}} \left(\alpha + \beta\right)$ and $\braket{ i \mid r} = \frac{1}{\sqrt{2}}\left(\alpha^* + \beta^*\right)$, it follows that $\frac{1}{2} = \braket{i \mid r} \braket{r \mid i} = \frac{1}{2}\left(\alpha^* \alpha + \beta^* \beta + \alpha^* \beta + \alpha \beta^*\right)$ and thus that $\alpha^* \beta + \alpha \beta^* = 0$.
		      Since $\braket{o \mid r} \braket{r \mid o} = \frac{1}{2}\left(\gamma^* \gamma + \delta^* \delta + \gamma^* \delta + \gamma \delta^*\right)$, it follows that $\gamma^* \delta + \gamma \delta^* = 0$.
		\item Since $\left(\alpha^* \beta\right)^* = \alpha \beta^*$, the above result implies that $\alpha^* \beta$ is a pure imaginary number under the convention that $0$ is also pure imaginary.
		      Similarly, the number $\gamma^* \delta$ is pure imaginary under the same convention.
	\end{enumerate}
	Since $\alpha^* \beta$ is pure imaginary, the coefficients $\alpha$ and $\beta$ cannot both be real.
	Similarly, the coefficients $\gamma$ and $\delta$ cannot both be real.
\end{answer}

\subsection{Principles of quantum mechanics}

% characteristic polynomial
\begin{answer}
	To show for any Hermitian operator $L$ on an $N$-dimensional complex vector space that an orthonormal basis of $N$ vectors can be constructed from the eigenvectors of $L$, consider the base case in which $N=0$.
	Since $H = \left\{0\right\}$, the empty set is an orthonormal basis of $N$ vectors and the result follows.
	For the sake of induction, suppose for any Hermitian operator on any $(N-1)$-dimensional complex vector space that an orthonormal basis of $(N-1)$ vectors can be constructed from its eigenvectors.

	Let $L$ be a Hermitian operator on an $N$-dimensional complex vector space $H$.
	Since $H$ is finite-dimensional over $\C$, the characteristic polynomial $p$ of $L$ has degree $N$.
	By the fundamental theorem of algebra, the operator $L$ has at at least one eigenvalue $\lambda_n \in \C$.
	Since $L$ is Hermitian, the eigenvalue $\lambda_n$ is real.
	Let $\ket{\lambda_n} \in \p{H \setminus \{0\}}$ be an eigenvector of $\lambda_n$, $V_n = \op{span}\left\{\ket{\lambda_n}\right\}$, and $H_{n-1} = V_n^\perp$ be the orthogonal complement of $V_n$ in $H$.
	Since $L \ket{\lambda_n} = \lambda_n \ket{\lambda_n}$, interchanging bras and kets yields $\bra{\lambda_n} L = \lambda_n \bra{\lambda_n}$ since $L$ is Hermitian and $\lambda_n$ is real.
	If $\ket{A} \in H_{n-1}$ and hence $\braket{\lambda_n \mid A} = 0$, then it satisfies $\braket{\lambda_n \mid L A} = \lambda_n \braket{\lambda_n \mid A} = 0$.
	Hence, $L\p{H_{n-1}} \subseteq H_{n-1}$.
	Thus, the linear operator $L$ is defined on the $(N-1)$-dimensional complex vector space $H_{n-1}$ and it is Hermitian on $H_{n-1}$.
	By the inductive hypothesis, an orthonormal basis $B_{n-1}$ can be constructed from the eigenvectors of $L$ on $H_{n-1}$.
	Thus, the union $\dsp B_{n-1} \cup \left\{\frac{1}{\|\ket{\lambda_n}\|} \ket{\lambda_n} \right\}$ is an orthonormal basis of $H$ consisting of eigenvectors of $L$.
	Therefore, the result follows by induction.
\end{answer}

% solution
\begin{answer}
	Let $\sigma_z$ be a linear operator satisfying the equations below.
	\begin{align}\label{eqn:sz}
		\sigma_z
		\begin{pmatrix}
			1 \\
			0
		\end{pmatrix}
		=
		\begin{pmatrix} 1 \\ 0 \end{pmatrix}
		\qquad
		\sigma_z
		\begin{pmatrix}
			0 \\
			1
		\end{pmatrix}
		= -
		\begin{pmatrix}
			0 \\
			1
		\end{pmatrix}
	\end{align}
	It follows from the first equation above that $\p{\sigma_z}_{11} = 1$ and $\p{\sigma_z}_{21} = 0$.
	It follows from the second equation that $\p{\sigma_z}_{12} = 0$ and $\p{\sigma_z}_{22} = -1$.
	By construction of $\sigma_z = \begin{pmatrix} 1 & 0 \\ 0 & -1 \end{pmatrix}$, it satisfies Equations \eqref{eqn:sz}.
	It is the unique matrix satisfying them.
\end{answer}

% one parameter for each eigenvector 
\begin{answer}
	Consider the linear operator given in some basis as follows.
	\begin{align}
		\sigma_n & =
		\begin{pmatrix}
			\cos \theta & \sin \theta  \\
			\sin \theta & -\cos \theta
		\end{pmatrix}
	\end{align}
	The characteristic polynomial $\det\p{\sigma_n - \lambda I} = \p{\cos \theta - \lambda}\p{- \cos \theta - \lambda} - \sin^2 \theta = \lambda^2 - 1$ yields eigenvalues $\lambda_1 = 1$ and $\lambda_2 = -1$.
	Assuming the eigenvector $\ket{\lambda_1}$ has the form $\ket{\lambda_1} = \begin{pmatrix} \cos \alpha \\ \sin \alpha \end{pmatrix}$ yields the equation $\sigma_n \ket{\lambda_1} = \lambda_1 \ket{\lambda_1}$, which is expanded below.
	\begin{align}\label{eqn:eigen}
		\begin{pmatrix}
			\cos \theta \cos \alpha + \sin \theta \sin \alpha \\
			\sin \theta \cos \alpha - \cos \theta \sin \alpha
		\end{pmatrix}
		 & =
		\begin{pmatrix}
			\cos \alpha \\
			\sin \alpha
		\end{pmatrix}
	\end{align}
	Since
	$\sigma_n \ket{\lambda_1} = \begin{pmatrix}
			\cos\p{\theta - \alpha} \\
			\sin\p{\theta - \alpha}
		\end{pmatrix}$,
	solving the above equations for $\alpha$ yields $\alpha_1 = \frac{\theta}{2} - \pi k_1$ for integer $k_1 \in \Z$.
	This yields an eigenvector $\ket{\lambda_1} = \begin{pmatrix} \cos \alpha_1 \\ \sin \alpha_1 \end{pmatrix}$ determined by integer $k_1$.
	Any integer $k_1$ determines such an eigenvector, and this choice affects only the sign.

	Setting $\sigma_n \ket{\lambda_2} = - \ket{\lambda_2} = - \begin{pmatrix} \cos \alpha \\ \sin \alpha \end{pmatrix}$ and solving
	$
		\begin{pmatrix}
			\cos\p{\theta - \alpha} \\
			\sin\p{\theta - \alpha}
		\end{pmatrix}
		=
		\begin{pmatrix}
			- \cos \alpha \\
			- \sin \alpha
		\end{pmatrix}
	$
	yields $\alpha_2 = \frac{\theta - \pi}{2} - \pi k_2$ for each integer $k_2 \in \Z$, each of which determines an
	eigenvector $\ket{\lambda_2} = \begin{pmatrix} \cos\p{\alpha_2} \\ \sin\p{\alpha_2} \end{pmatrix}$.
	Any eigenvector of $\sigma_n$ is determined by some choice of integer $k_2$, and this choice controls only the sign of the eigenvector.
	It was sensible to assume a single parameter $\alpha$ since the two components of a normalized eigenvector are related by the constraint of unit length.
\end{answer}

\begin{answer}
	Let $n_z = \cos \theta$, $n_x = \sin \theta \cos \phi$, and $n_y = \sin \theta \sin \phi$, and observe that $\sigma_n = \begin{pmatrix} n_z & \p{n_x - i n_y} \\ \p{n_x + i n_y} & - n_z \end{pmatrix}$ is given below.
	\begin{align*}
		\sigma_n & =
		\begin{pmatrix}
			\cos \theta             & e^{-i \phi} \sin \theta \\
			e^{i \phi } \sin \theta & - \cos \theta
		\end{pmatrix}
	\end{align*}
	Calculation yields $\sigma_n \sigma_n = I$.
	Thus, the roots of the characteristic polynomial $\det\p{\sigma_n - \lambda I}$ are $\lambda_1 = 1$ and $\lambda_2 = -1$.
	Suppose $\ket{\lambda_1} = \begin{pmatrix} \cos \alpha \\ e^{i \beta} \sin \alpha \end{pmatrix}$ solves the equation $\sigma_n \ket{\lambda_1} = \lambda_1 \ket{\lambda_1}$, which is expanded below.
	\begin{align*}
		\begin{pmatrix}
			\cos \theta \cos \alpha + e^{i(\beta - \phi)} \sin \theta \sin \alpha \\
			e^{i \phi} \sin \theta \cos \alpha - e^{i \beta} \cos \theta \sin \alpha
		\end{pmatrix}
		=
		\begin{pmatrix}
			\cos \alpha \\
			e^{i \beta} \sin \alpha
		\end{pmatrix}
	\end{align*}
	This yields $\beta = \phi + 2 \pi k_\beta$ for any integer $k_\beta \in \Z$, $\alpha = \frac{\theta}{2} + \pi k_\alpha$ for any integer $k_\alpha \in \Z$, and choosing $k_\alpha = k_\beta = 0$ yields $\ket{\lambda_1} = \begin{pmatrix} \cos \frac{\theta}{2} \\ e^{i \phi} \sin \frac{\theta}{2} \end{pmatrix}$.
	Similarly, we obtain $\ket{\lambda_2} = \begin{pmatrix} \sin \frac{\theta}{2} \\ - e^{i \phi} \cos \frac{\theta}{2} \end{pmatrix}$.
	Each eigenvector of $\sigma_n$ is unique up to a complex phase and normalization.
\end{answer}

\begin{answer}
	Suppose that a spin is prepared so that $\sigma_m = +1$.
\end{answer}

